---
title: "第八章、马尔可夫链蒙特卡罗"
author: "李洁"
date: "2022/3/20"
geometry: "left=2cm,right=2cm,top=2cm,bottom=2cm"
output: 
      html_document : 
        toc: yes
        toc_float: yes
        toc.depth: 6
        toc_depth: 6
        theme: paper
        df_print: tibble
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	comment = " ",
	prompt = TRUE,
	results = "hold"
)
```

概率总是一个不那么让人喜欢的东西。在神话中，只有亡命之徒采取乞求幸运女神，而大多数人只相信智慧女神。当然，对科学而言，其应该是智慧女神的领地，幸运女神在科学领域毫无作用。

但是直到20世纪，两个完全对立的女神开始了合作。作为智慧女神的拥护者，科学家们开始写关于随机数的书，开始使用随机的观点来研究客观世界。直到现在，智慧和运气变成了完全合作的关系。没有人在质疑随机在科学研究中的作用。从天气预报、到金融领域、再到生物进化领域，每一个领域都充斥了随机的过程。

本章通过一种随机过程来研究后验概率分布的估计。该过程就是大名鼎鼎的马尔可夫链蒙特卡罗Markov chain Monte Carlo(MCMC)。本章将在后验概率模型中随机抽样进行后验概率估计，而不必像之前那样需要对模型的模型参数进行极大化处理。也不需要依赖具体的后验概率分布形式（比如正态分布等）。由于避免了正态假设，这对广义线性模型和多水平模型的后验概率分布估计很有帮助。当然，这样做带来的代价就是计算量的大大增加，完成一个估计可能需要较长的时间。

本章MCMC的估计是通过R语言rethinking包的map2stan函数来实现的，其实是使用的STAN软件。

## 8.1 国王与岛屿

一个很爱民的国王拥有10个岛屿的领地，这10个岛屿相互环绕组成一个环。(如下图)

[![bLRYAH.png](https://s1.ax1x.com/2022/03/14/bLRYAH.png)](https://imgtu.com/i/bLRYAH)

每个岛屿的大小不同，每个岛屿上的人口也不同，第一个岛屿最小，人口最少，第二个人口第二少，以此类推，到最后一个岛屿，其最大，人口也最多，是第一个岛人口数的10倍。这位爱民的国王去视察他的子民，但是为了一视同仁，避免偏见，他决定在每个岛上停留的时候应该和该岛的人口数成正比，人口越多的岛（如第10个岛），应该停留时间最长。

当然，这也不难，做一个年度计划，按照人口数大小确定在每一个岛上待的时间即可。

但是，这为国王并不喜欢死板而又长远的计划，他只希望当他在一个岛上待了一段时间后，再临时决定去其他岛，而且他只会去邻近的岛，不会跨岛移动。只要最后保证在某个岛上待的总时间和岛上人口数成比例即可。

那么，这位国王该怎么做呢？？

还好，这位国王有一位聪明的大臣叫Metropolis，他很快找到了一种方法，能够在不作出行计划的情况下，达到国王的要求。他是这么做的：

1）不管国王现在在哪个岛上，每待完一周后，他就要考虑下一周的行程：要么在该岛上继续待一周，要么去邻近的一个岛屿。如果是去邻近的岛屿，他会通过掷硬币来决定下周去相邻两个岛中的一个。如果硬币正面朝上，那么他会按照顺时针方向移动到邻近岛上；如果反面朝上，他会按照逆时针方向移动到邻近岛上。这个有掷硬币决定的岛，我们称之为”目标岛”。

2）那么为了决定国王是否移动换岛，他是这么做的。按照目标岛上的人口比例把一些贝壳放在了一个黑色袋子中；比如，如果他通过掷硬币决定应该去9号岛，那么他就把9个贝壳放在袋子中。同样的，他按照当前岛上人口比例把一些石子放在同一个袋子中；比如他现在在10号岛，那么他在袋子中又加入了10个石子。

3）如果袋子中贝壳比石子多，那么国王就会毫不犹豫的去目标岛屿。但是如果贝壳比石子少，他就会按照贝壳的数量来丢掉袋子中的石子，比如袋子中有4个贝壳和6个石子，那么他会丢带4个石子，最终袋子中剩余4个贝壳和（6-4）= 2个石子。然后他在袋子中随机抽取一个物体，如果是贝壳，那么他就会移动到目标岛屿；而如果是石子，他变会在该岛上继续待一周。

这个过程看似很复杂，但它确实十分有效。国王每次移动看起来是随机的，要么接着待在该岛，要么随机去邻近岛屿。但是长期过程来看，他达到了目的：不需要制定死板的长期行程规划，最终在每个岛上停留的时间和该岛上的人口数量成正比！

##  8.2补充：Metropolis采样算法

###  8.2.1 Metropolis采样算法的思路

Metropolis采样算法的基本思路是：从一个已知的形式较为简单的分布中采样，并以一定的概率接受这个样本作为目标分布的近似样本。现在我们有一个形式较为简单的对称分布$\theta(x)$，转移概率矩阵Q为平稳分布，从中采样得到一个候选样本，以一定的概率选择接受或拒绝这个候选样本。一般这个接受的概率定位，当随机生成的一个概率值小于指定的概率时，接受这个候选样本，否则拒绝这个候选样本。

$\theta(x)$的转移概率矩阵为Q，随机变量从状态$s_i$转移到$s_j$的转移概率为$Q_{ij}$，随机变量从状态$s_i$转移到$s_j$的接受概率为$\alpha_{ij}$，我们借助于$Q_{ij}$和$\alpha_{ij}$得到的转移概率$P_{ij}$和$Q_{ij}$、$\alpha_{ij}$有如下关系：：
$$ P_{ij} =\alpha_{ij} *Q_{ij} $$
其中，$\alpha_{ij}$为上述已知的分布，$Q_{ij}$为：
$$Q_{ij}=q(\theta ^{(j)}∣\theta ^{(i)})$$

只要满足：保证概率矩阵P满足细致平稳条件$\Pi(i)P_{ij}=\Pi(j)P_{ji}$,那么P的平稳分布就是目标分布$\Pi(x)$，马尔可夫收敛后的样本也是目标分布$\Pi(x)$的样本。

因此，转移概率矩阵P的平稳分布为$\Pi(x)$，以上述方式获得的马尔可夫收敛后的样本序列为目标分布$\Pi(x)$的近似样本。

###  8.2.2 Metropolis采样算法步骤

step1.初始化：t=0，随机生成一个$x_0$赋值给当前的$x_t$，迭代终止条件为$t=T$

step2.令$t=t+1$，从条件概率分布$\Theta(x|x_{t-1})$中生成候选样本$\hat{x}$

step3.计算接受概率$\alpha$,$\alpha=(1,\frac{\pi(\hat{x})}{\pi(x_{t-1})})$

step4.从均匀分布中生成一个随机数$\alpha_t$

step5.若$\alpha_t \le \alpha$，则接受候选样本，$x_t=\hat{x}$,否则，拒绝候选样本并令$x_t=x_{t-1}$

step6.若$t=T$，停止迭代，否则回到第2步继续迭代。

停止迭代后，生成了样本序列，根据需要截取尾部的n个样本，这n个样本可以近似地认为是从目标分布中采样得到的。

下面我们通过代码来模拟这一过程。下面的短代码模拟国王一系列的访问位置，模拟的结果存在变量position中：

```{r}
num_weeks <- 1e5  #取100000个数
positions <- rep(0,num_weeks)#取100000个0
head(positions)
```
```{r}
current <-10 #起始岛屿，这里设置的为最大的10号岛屿
for( i in 1:num_weeks){
  #记录当前的位置
   positions[i] <- current
  # 掷硬币决定去向
   proposal <- current + sample(c(-1,1),size = 1)
  # 连接环状首尾，保证编号是在1-10之间循环
   #如果得到的是岛屿“0”，则自动切换到岛屿10
   if(proposal<1) proposal <- 10
   #如果得到的是岛屿“11”，则自动切换到岛屿1
   if(proposal>10) proposal <- 1        
  #决定去还是留
  prob_move <- proposal/current
  #抽取一个[0,1]上的随机变量，如果随机数小于下一个岛屿编号和当前岛屿编号的比值，国王就会出发前往下一个岛屿
  current <- ifelse(runif(1) < prob_move, proposal, current)
}

```

[![bLbB7t.png](https://s1.ax1x.com/2022/03/14/bLbB7t.png)](https://imgtu.com/i/bLbB7t)

左图显示的国外在最初100个周内所处的岛，看起来是杂乱无章，没有规律可循的。但是当该过程进行10万周后，你会发现最终在每个岛屿上停留的时间和岛屿标号（即人口数）成正比，如右图。

实际上，如果国王不是选择邻近岛屿，而是随机选择任意岛屿，上述结果也依旧成立。只要按照目标岛屿和当前岛屿人口数的比例来作为移动的概率，最后结果都是一样的，即结果收敛。甚至即便国王不知道他一共有多少的岛屿，上述方法依旧可行。所以，只要国王知道当前岛屿人口和目标岛屿人口，照此移动即可，不在需要知道之前或者之后的其他岛屿的人口数！这就是一个简化的马尔科夫链蒙特卡罗！

## 8.3 马尔可夫链蒙特卡罗

上述例子中实现MCMC的方法也就叫做Metropolis算法，通过它可以在一个未知或者极其复杂的分布中进行高效抽样。

其中“岛”就是概率分布的参数值，可以是离散的，也可以是连续的；“人口数”就是每一个参数值的后验概率；“周”是模型中联合后验概率分布的样本。通过抽样就可以估计后验概率分布，进而可以进行参数估计等其他应用。

从未知分布的后验概率中抽样的方法有很多种，但是Metropolis算法是其他抽样方法的始祖。除了Metropolis算法，还有Gibbs抽样和Hamiltonian抽样。这两种方法在贝叶斯统计中也经常用到。

###  8.3.1 Gibbs抽样

Metropolis算法中从A移动到B和从B移动到A的概率是相等（对称）的。该方法更广泛的应用是Metropolis-Hastings方法，它不要求双向移动概率相等，即在上述例子中，国王使用的硬币可以是一个“不公平”的硬币。

双向移动概率的不对称在我们的实际应用很重要，能够使我们更容易处理一些有边界的参数，比如标准差。而处理这种不对称最常用的方法就是“Gibbs抽样”。它是Metropolis-Hastings方法的一个改进，能够更加高效的抽样。在实际使用中，很多贝叶斯模型软件，比如BUGS和JAGS都是使用的Gibbs抽样方法。

### 补充：

1、重新寻找合适的细致平稳条件

在上面我们提到了如果非周期马尔可夫链的状态转移P和概率分布$\Pi(x)$对于所有的i,j满足：$\Pi(i)P(i,j)=\Pi(j)P(j,i)$，则称概率分布$\Pi(x)$是状态转移矩阵P的平稳分布。

在Metropolis中我们通过引入接受率使得细致平稳条件满足。现在我们换一个思路。

从二维的数据分布开始，假设$\pi(x1,x2)$ 是一个二维联合数据分布，观察第一个特征维度相同的两个点$A(x_1^{(1)},x_2^{(1)})$和$B(x_1^{(1)},x_2^{(2)})$，容易发现下面两式成立：

$$π(x_1^{(1)},x_2^{(1)})π(x_2^{(2)}|x_1^{(1)})=π(x_1^{(1)})π(x_2^{(1)}|x_1^{(1)})π(x_2^{(2)}|x_1^{(1)})$$
$$π(x_1^{(1)},x_2^{(2)})π(x_2^{(1)}|x_1^{(1)})=π(x_1^{(1)})π(x_2^{(2)}|x_1^{(1)})π(x_2^{(1)}|x_1^{(1)})$$ 
由于两式的右边相等，因此我们有：
$$π(x_1^{(1)},x_2^{(1)})π(x_2^{(2)}|x_1^{(1)})=π(x_1^{(1)},x_2^{(2)})π(x_2^{(1)}|x_1^{(1)})$$
也就是：
$$\pi(A)\pi(x_2^{(2)}|x_1^{(1)})=\pi(B)\pi(x_2^{(1)}|x_1^{(1)})$$
观察上式再观察细致平稳条件的公式，我们发现在$x_1=x_1^{(1)}$这条直线上，如果用条件概率分布$π(x_2|x_1^{(1)})$作为马尔可夫链的状态转移概率，则任意两个点之间的转移满足细致平稳条件！同样的道理，在$x_2=x_2^{(1)}$这条直线上，如果用条件概率分布$π(x_1|x_2^{(1)})$作为马尔可夫链的状态转移概率，则任意两个点之间的转移也满足细致平稳条件。那是因为假如有一点$C(x_1^{(2)},x_2^{(1)})$,我们可以得到：
$$\pi(A)\pi(x_1^{(2)}|x_2^{(1)})=\pi(C)\pi(x_1^{(1)}|x_2^{(1)})$$
基于上面的发现，我们可以这样构造分布$π(x_1,x_2)$的马尔可夫链对应的状态转移矩阵P：
$$ P(A→B)=π(x_2^{(B)}|x_1^{(1)}) 
if X_1^{(A)}=X_1^{(B)}=X_1^{(1)}$$
 
$$P(A→C)=π(x_1^{(C)}|x_2^{(1)}) 
if X_2^{(A)}=X_2^{(C)}=X_2^{(1)}$$
$$ P(A→D)=0else$$
有了上面这个状态转移矩阵，我们很容易验证二维平面上的任意两点E,F，满足细致平稳条件时：
$$π(E)P(E→F)=π(F)P(F→E)$$
于是这个二维空间上的马氏链将收敛到平稳分布$ \pi(x,y)$

#### 8.3.1.1 二维的Gibbs采样

利用上面找到的状态转移矩阵，我们就得到了二维Gibbs采样，这个采样需要两个维度之间的条件概率。具体过程如下：

1）输入平稳分布$π(x_1,x_2)$，设定状态转移次数阈值$n_1$，需要的样本个数$n_2$

2）随机初始化初始状态值$x_1^{(0)}$和$x_2^{(0)}$

3）for $t=0$ to $n_1+n_2−1$: 

　　a) 从条件概率分布$P(x_2|x_1^{(t)})$中采样得到样本$x_2^{(t+1)}$
　　　　　
　　b) 从条件概率分布$P(x_1|x_2^{(t+1)})$中采样得到样本$x_1^{(t+1)}$
　　　　　
样本集
$${(x_1^{(n_1)},x_2^{(n_1)}),(x_1^{(n_1+1)},x_2^{(n_1+1)}),...,(x_1^{(n_1+n_2-1},x_2^{(n_1+n_2-1)})}$$
即为我们需要的平稳分布对应的样本集。

整个采样过程中，我们通过轮换坐标轴，采样的过程为：
$$(x_1^{(1)},x_2^{(1)})→(x_1^{(1)},x_2^{(2)})→(x_1^{(2)},x_2^{(2)})→...→(x_1^{(n_1+n_2-1)},x_2^{(n_1+n_2-1)})$$

用下图可以很直观的看出，采样是在两个坐标轴上不停的轮换的。当然，坐标轴轮换不是必须的，我们也可以每次随机选择一个坐标轴进行采样。不过常用的Gibbs采样的实现都是基于坐标轴轮换的。

[![qrCVdU.png](https://s1.ax1x.com/2022/03/28/qrCVdU.png)](https://imgtu.com/i/qrCVdU)

#### 8.3.1.2 多维的Gibbs采样

上面的这个算法推广到多维的时候也是成立的。比如一个n维的概率分布$\pi(x_1,x_2,...x_n)$，我们可以通过在n个坐标轴上轮换采样，来得到新的样本。对于轮换到的任意一个坐标轴$x_i$上的转移，马尔科夫链的状态转移概率为$P(x_i|x_1,x_2,...,x_{i−1},x_{i+1},...,x_n)$，即固定n−1个坐标轴，在某一个坐标轴上移动。

具体的算法过程如下：

1）输入平稳分布$\pi(x_1,x_2，...,x_n)$或者对应的所有特征的条件概率分布，设定状态转移次数阈值$n_1$，需要的样本个数$n_2$

2）随机初始化初始状态值$(x_1^{(0)},x_2^{(0)},...,x_n^{(0)})$

3）for $t=0$ to $n_1+n_2−1$:  

　a) 从条件概率分布$P(x_1|x_2^{(t)},x_3^{(t)},...,x_n^{(t)})$中采样得到样本$x_1^{t+1}$
　
　b) 从条件概率分布
　$P(x_2|x_1^{(t+1)},x_3^{(t)},...,x_n^{(t)})$中采样得到样本$x_2^{(t+1)}$
　　　　　
　c)...

　d) 从条件概率分布$P(x_j|x_1^{(t+1)},x_2^{(t+1)},...,x_{j-1}^{(t+1)},x_{j+1}^{(t)},...,x_n^{(t)})$中采样得到样本$x_j^{(t+1)}$

　e)...

　f) 从条件概率分布$P(x_n|x_1^{(t+1)},x_2^{(t+1)},...,x_{n-1}^{(t+1)})$中采样得到样本$x_n^{t+1}$
　
样本集$$(x_1^{(n_1)},x_2^{(n_1)},...,x_n^{(n_1)}),...,(x_1^{(n_1+n_2-1},x_2^{(n_1+n_2-1)},...,x_n^{(n_1+n_2-1)})$$,即为我们需要的平稳分布对应的样本集。

整个采样过程和Lasso回归的坐标轴下降法算法非常类似，只不过Lasso回归是固定n−1个特征，对某一个特征求极值。而Gibbs采样是固定n−1个特征在某一个特征采样。

同样的，轮换坐标轴不是必须的，我们可以随机选择某一个坐标轴进行状态转移，只不过常用的Gibbs采样的实现都是基于坐标轴轮换的。

#### 8.3.1.3 Gibbs采样的缺点

Gibbs方法的缺点是，需要联合先验概率，而先验概率的选择对很对不太了解贝叶斯的人来说往往很难接受。其次，随着模型变得复杂，比如含有成百上千个参数的模型，那么Gibbs的抽样变得效率非常低。这时，我们就应该考虑其他的抽样方法了。

#### 8.3.1.4 Gibbs采样的小结

Gibbs采样是接受概率为1的Metropolis算法，是MCMC算法的分解形式：

假设我们有多个随机数组成的联合分布$p(\beta,\gamma,\sigma,...,Z)$,我们给定其中任何一个分布，如$p(Z)$,$P(\sigma | Z)$,$P(\gamma|....)$依次进行下去，可以将上述的联合分布拆分成多个条件分布，进行联合抽取过程。其中的每一个条件分布都可记作是M-H算法，这就是Gibbs抽样的过程。

### 8.3.2 Hamiltonian蒙特卡罗

“当通过随机的过程做一件事的时候，似乎也总能通过非随机的方式来做，只不过非随机的方式需要我们更多的智慧”

Metropolis和Gibbs的方法都是高度随机的过程，通过尝试不同的新的参数，然后和当前值比较。只不过，Gibbs方法使用先验概率，相对降低了一定的随机性，以此换来了更高的效率。

相比之下，Hamiltonian方法（HMC）更为高效，只需要更少的抽样便可很好的对后验概率分布进行描述，特别是在参数很多的时候，Hamiltonian方法的效率远远胜于其他方法。

Hamiltonian/Hybrid Monte Carlo (HMC) 是一种 MCMC 方法，它采用物理系统动力学而不是概率分布来提出马尔可夫链中的未来状态。这允许马尔可夫链更有效地探索目标分布，从而更快地收敛。在这里，我们首先了解一下哈密顿力学的相关概念。

####  8.3.2.1 哈密顿力学

哈密顿力学是利用给定物体在时刻t的位置x和速度v来描述其运动过程，由于位置x和速度v分别对应着势能和动能，将势能和动能分别描述为关于位置x和速度v的函数，则势能为$U(x)$,动能为$K(v)$,系统的总能量为$$ H(x,v)=U(x)+K(v)$$
因此，位置x和速度v有独立的正则分布，即
$$ p(x,v) \propto exp(\frac {-H(x,v)}{T})
=exp(\frac{-U(X)}{T})exp(\frac{-K(v)}{T})
\propto p(x)p(v)$$
利用x和v的分布即可对联合分布进行采样。

以速度v为例，由于正则分布中的随机变量x和v相互独立，在哈密顿力学中，若选择标准正态分布为速度v的基本假设，则动能对应的函数为
$$ K(v)=-log p(v) \propto \frac{v^Tv}{2}$$
类似地，我们可以定义势能函数为$U(x)=-log p(x)$,如果要单独对随机变量x采用HMC算法，还需要计算出关于速度信息的$-\frac{\partial log p(x)}{\partial x_i}$

#### 8.3.2.2 模拟哈密顿动力学——Leap Frog 方法

哈密顿方程描述了物体在时间上的运动，它是一个连续变量。为了在计算机上数值模拟哈密顿动力学，有必要通过离散时间来近似哈密顿方程。这是通过将区间T拆分为一系列较小的长度区间来完成的。$\delta$值越小，$\delta$越接近连续时间的动态。已经开发了许多用于离散时间的程序，包括欧拉方法和 Leap Frog Method。Leap Frog 方法依次更新动量和位置变量，首先模拟一小段时间的动量动力学$\frac{\delta}{2}$，然后在稍长的时间间隔内模拟位置动力学$\delta$，然后在另一个小时间间隔内完成动量模拟.因此x和 p现在存在于同一时间点。具体来说，Leap Frog 方法如下： 1. 时间走半步更新动量变量：
$$p_i(t+\delta/2)=p_i(t)-(\delta/2) \frac{\partial U}{\partial x_i(t)}$$
2.及时整步更新位置变量
$$ x_i(t+ \delta)=x_i(t)+\delta \frac{\partial K}{\partial p_i(t+\delta/2)}$$
3.将剩余的半步及时完成更新动量变量
$$ p_i(t+\delta)=p_i(t+\delta/2)-(\delta/2)\frac{\partial U}{\partial x_i(t+\delta)}$$
可以运行 Leap Fog 方法L以模拟$L \times \delta$单位时间内的动态。这种特殊的离散化方法具有许多特性，使其优于其他近似方法，如欧拉方法，特别是在 MCMC 中使用。

#### 8.3.2.3 Hamiltonian蒙特卡罗

在 HMC 中，我们使用哈密顿动力学作为马尔可夫链的提议函数，以便 比使用提议概率分布更有效地探索由$p(x)$定义的目标（规范）密度。$U(x)$从初始状态开始$[x_0,p_0]$,我们使用 Leap Frog 方法在短时间内模拟哈密顿动力学。然后，我们在模拟结束时使用位置和动量变量的状态作为我们提出的状态变量$x^*$和$p^*$。使用类似于 Metropolis 接受标准的更新规则接受提议的状态。特别是如果在哈密顿动力学之后提出的状态的概率

$$ p(x^*,p^*)\propto e^{-[U(x^*)+Kp^*]}$$
大于哈密顿动力学之前状态的概率
$$ p(X_0,P_0) \propto e^{-[U(x^{(t-1)}),K(P^{(t-1)})]}$$
然后接受提议的状态，否则随机接受提议的状态。如果状态被拒绝，则将马尔可夫链的下一个状态设置为状态 at (t-1)。对于给定的一组初始条件，哈密顿动力学将遵循相空间中恒定能量的轮廓。因此，我们必须随机扰动动力学以探索所有p(x). 这是通过p(P)  在每次采样迭代之前运行动力学之前简单地从相应的规范分布中提取随机动量来完成的t。结合这些步骤，采样随机动量，然后是哈密顿动力学和 Metropolis 接受准则，定义了用于绘图的 HMC 算法,M来自目标分布的样本：

1.放$t=0$

2.生成初始位置状态$X^{(0)} \sim \pi^{(0)}$

3.重复直到t=M

  放t=t+1

   -从动量规范分布中采样一个新的初始动量变量$P_0 \sim  p(P)$
 
   -放$X_0=X^{(t-1)}$
   
   -运行Leap Frog算法，从$[X_0,P_0]$for Lsteps和stepsize开始，$\delta$以获得建议的状态$X^*$和$P^*$
   
   计算Metropolis接受概率：
    $$ \alpha =min(1,exp(-U(x^*)+U(x_0)-K(P^*)+k(P_0)))$$
     $\mu$-从中抽取一个随机数$Unif(0,1)$
     
  如果$\mu \le \alpha$ 接受提议的状态位置$X^*$并设置马尔可夫链中的下一个状态$X^{(t)}=X^*$
  
  其他设置$X^{(t)}=X^{(t-1)}$
  
回到之前的例子，现在有另一个国王，不过该国王领土位于陆地上，而不是离散的岛屿。他和之前的国王一样，也想按照一个地区的人口数量来确定在一个地区停留视察的时间。有一个大臣给他出了一个主意，根据一个地区房屋密度来确定行驶速度，在房屋密度大的地方，减慢速度；在房屋稀疏的地方，加快行驶速度。这就需要国王时刻了解当前地点的房屋密度，但是不需要知道他现在具体在什么位置了，也不需要知道其他地方的房屋密度。通过这种方法，国王实际上可以按照人口密度遍历整个国家的领土。

这就是Hamiltonian方法的一个简化模型。国王的行驶就是当前的一个参数，就好比一个碗，一个球要遍历整个碗的内表面，在较高的位置，球的运行速度较低，在较低的位置球的运行速度较高。

而Hamiltonian方法确实就是按照这种方法来遍历一个后验概率分布的。如果后验概率分布比较平（比如似然函数或者先验概率无法提供足够的信息），那么该方法需要遍历很大的一个空间，相反，如果后验概率分布很陡峭，那么该方法遍历的空间会很小，效率会很高。

Hamiltonian方法的缺点是，它需要连续的参数空间，对于离散的参数分布，它无法进行遍历。此外，Hamiltonian方法还需要进行调参，一个好的初始参数能够大大提高抽样效率。手动调参是一个很麻烦的过程，不过还好STAN软件可以进行自动调参。

实际上，马尔可夫链蒙特卡洛并不是新鲜事物，只不过其大规模应用比较晚，在开始20世世纪末才大范围使用。现在仍然有很多MCMC方法的变体和改进出现。相信在不久的将来会有更好的方法来替代Gibbs抽样和Hamiltonian方法。

##  8.4 初始HMC:map2stan

R语言的rethinking包可以通过map2stan来实现HMC。之前的文章中介绍过国家地形平整度和GDP关系的例子，当时是通过map函数的平方估计来实现的。

```{r}
library(rethinking)
```

```{r}
#载入数据
data("rugged")
d <- rugged#地势崎岖
d$log_gdp <- log(d$rgdppc_2000)#2000年人均GDP对数
dd <- d[complete.cases(d$rgdppc_2000),]#删除缺失数据之后的完整数据
```

```{r}
m8.1 <- map(
 alist(
 log_gdp <- dnorm(mu,sigma),
 mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa,
 a ~ dnorm(0,100),
 bR ~ dnorm(0,10),
 bA ~ dnorm(0,10),
 bAR ~ dnorm(0,10),
 sigma ~ dunif(0,10)
 ),
 data = dd
)

precis(m8.1)


```

下面是通过map2stan来实现HMC的过程。

### 8.4.1 数据准备

由于这里不再使用平方估计的方法，所以如果后验概率是非正态分布，那么我们抽样得到的也最终会是非正态分布。不过在做之前，要首先预处理一下数据。包括数据形式的变换和剔除数据框中不必要的变量（列）。虽然这不是必要的，但是为了防止一些难以预料的错误，我们最好还是把数据整理清洗干净。

以下是以地势崎岖度数据集为例的代码：

```{r}
dd.trim<-dd[,c("log_gdp","rugged","cont_africa")]#数据框中只包含我们需要的3个变量
str(dd.trim)#生成的是170*3的一个数据框
```
### 8.4.2 模型估计

```{r}
m8.1stan <- map2stan(
 alist(
 log_gdp ~ dnorm(mu, sigma),
 mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa,
 a ~ dnorm(0,100),
 bR ~ dnorm(0,10),
 bA ~ dnorm(0,10),
 bAR ~ dnorm(0,10),
 sigma ~ dcauchy(0,2)
 ),
 data = dd.trim
)


```
除了函数名从之前的map变成了map2stan，其他变化不大。不过注意sigma的先验分布类型从之前的均匀分布变成了cauchy分布，该分布和T分布很相似，只不过分布的尾部密度比较高。当然，这儿如果继续使用均匀分布也是可以的。

经过一系列的分析处理和等待，我们可通过下面的命令来查看模型结果：
```{r}
precis(m8.1stan)
```
和之前平方估计方法相比，结果相差不大。但是这儿多出了几样新东西。首先是这里的置信区间是最大后验概率密度区间（HPDI），而不是普通的百分区间（PI）。其次，结果还多出了两列n_eff和Rhat，这两列主要是MCMC模型诊断用的。其中Rhat应该是接近1的。

### 8.4.3 再次抽样

由于上面的模型比较简单，所以使用默认的1000次抽样就足够了。但是如果模型比较复杂，可能一次抽样并不足够，我们还需要多次抽样，建立多个马尔科夫链。这时，为了提高计算速度，我们使用多核并行抽样。

下面是对上述模型的重抽样，4核并行计算，建立4条马尔科夫链。

```{r}
m8.1stan_4chains <- map2stan(m8.1stan,chains = 4,cores = 4)
precis(m8.1stan_4chains)
```

### 8.4.4 可视化

通过对抽样的可视化，可以对结果有一个直观的感觉。通过extract.samples()函数对模型后验概率进行重抽样（默认1000次）。

```{r}
post <- extract.samples(m8.1stan)
str(post)
```


使用pairs函数一次性绘制所有的样本，函数会自动标注相应的变量名称和相关系数：
```{r}
pairs(post)
pairs(m8.1stan)
```

可视化图形给出了每一个参数的后验概率分布情况，并且给出了各个参数的相关性。就本例子而言，参数的后验概率十分接近于正态分布。

###  8.4.5 模型的使用

一旦你有了后验概率的一个样本，比如上面post对象，也就意味着你掌握了该模型，然后可以干很多事了，比如模拟预测、计算参数差异、计算DIC和WAIC等指标。

比如，通过show()函数可以直接得到模型的DIC和WAIC。

```{r}
show(m8.1stan)
```
### 8.4.6 链的核查

如果马尔可夫链使用正确，那么在一个长期的过程中，模型应该会收敛，即后验概率。否则模型就会出问题。

我们可以使用路径图来检验核查模型收敛情况。路径图即按抽样顺序做的图，通过路径图可以对每一个参数进行核查，如果没有发现问题，那么我们就可以放心的使用该链了。下面是我们上例模型中的路径图：

```{r}
plot(m8.1stan)
```
 
 其中灰色部分表示的前1000个样本，称之为“适应样本”。通过这些“适应样本”，马尔可夫链可以学习如何更有效的从后验概率分布中更有效的抽样，所以这些样本并不是用来最后预测的。白色区域代表用来进行推断的样本。

从上图地势崎岖模型对应的马尔可夫链的轨迹图中可以看出，该马尔可夫链表现良好，平稳且充分混合。

那么什么样的路径图是一个没有问题的路径图呢？我们一般查看两个方面：

1）稳定性 

2）混合性

稳定性是指路径存在于后验概率分布范围内，比如一直围绕在一个中心周围，或者你可以认为链的平均值从开始到最后一直都是稳定的。

混合性是指相邻样本之间没有很高的相关性。也就是路径应当弯弯折折。

满足以上两点的路径都是好的马尔可夫链，那么什么是不好的呢？

##  8.5 调试马尔可夫链

MCMC是通常是自动完成的，很多使用者或许并不知道其中发生了什么，其实也没有必要知道其中发生了什么。但是这并不意味着我们就可以放任模型不管了。

### 8.5.1 需要抽取多少样本

我们可以通过iter和warmup等参数来设置样本量，默认是2000个样本，其中一半样本用来“热身”，另一半用来推断。那么我们到底设置多少样本合适呢？

首先，我们要知道，真正的样本是“有效样本数量”，而不是你给的那个原始样本数。有效样本数是从后验概率分布中估计的独立样本数量，马尔可夫链通常是自相关的，所以序列样本并非完全独立。其中n_eff就是模型估计的有效样本数量，它通常会低于实际抽样样本数。

其次，所需样本数量大小还决定于你想要得到什么。如果你想要后验概率分布的均值，那么不需要太多的样本就可以达到你的目的。可能数百个样本就足够了。但是如果你关心整个后验概率分布的情况，那么你可以就需要很多样本了。具体多少样本没有统一的答案，一般认为在一个经典的回归分析中，你至少要有200个有效样本数量才能对后验概率做很好的估计。

“热身”warmup样本数量的设定也是一个需要考虑的问题。一个较小的“热身样本”数量就意味着你有更多地样本用来推测，但是这样可能会导致抽样效率的降低。在Stan软件中，总样本数的一半都可以身为“热身”样本。对于一些简单的模型，可能不需要那么多“热身”样本。所以具体还是根据实际情况来调整。

### 8.5.2 需要多少条马氏链

通常我们在估计模型的时候，会用到多个马尔可夫链，我们可以通过chains参数来设定链的数量，可以通过cores参数来设定并行处理的CPU数量，以此加快速度。那么我们到底应该设定多少条链合适呢？

首先，如果你是看模型是否能够运行，是否存在错误的地方，那么此时一条链就够了。如果你想看链是否达到了预期效果，那么就应该需要多个链了。如果上面两个都没问题，就可以开始进行模型拟合和推断了，此时一条链就足够了。当然，如果你偏要使用多个链，也是可以的。

具体来说，当第一次对一个模型使用一条链的时候，并不能够确定该链是否真的合适。此时应该使用多条链，然后分别查看链的路径图，看看它们是否都能够收敛到同一个分布中。如果一条链在一个分布中，另一条链在另一个分布中，此时模型就存在问题，需要重新思考模型的设置了。通常情况下，我们会使用3-4条链来检查各个链的收敛情况。一旦通过上面对多条链的检查，就可以放心的去使用一条链来拟合推断模型了。

比如，对一个模型我们需要1000个“热身”样本，9000个实际样本，那么我们是使用一条链（iter=10000, warmup=1000)还是使用3条链（iter=4000, warmup=1000)？其实对于推断来说，你用一条链和三条链都无所谓。但是它们实际运行效率可能不同，3条链的情况实际上有3000个“热身”样本，由于“热身”阶段是运行最慢的一个阶段，所以，如果使用3条链，可能导致运行效率比较低。当然，如果你能够把3条链进行多核并行处理，其运行速度会超过一条链的情况。

具体使用多少链还应该根据实际情况来决定。但是对于经典的回归模型，一般是“4条短链核查，1条长链推断”。

### 8.5.3 调试出错的马氏链（野链）

一个经常遇到的问题是后验概率分布是一个非常宽泛扁平的分布。这种情况的出现往往是由于使用的先验概率提供的信息太少，过于扁平。这就会导致一个野链，算法会错误的从一些极端参数值中大量抽样。

举一个例子，如果一个正态分布只有两个观测值，-1和1，这时就会出现野链。

```{r}
y <- c(-1,1)
m8.2 <- map2stan(
 alist(
 y ~ dnorm(mu, sigma),
 mu <- alpha
 ),
 data = list(y=y), start = list(alpha=0, sigma=1),
 chain = 2, iter = 4000, warmup = 1000
)
```

```{r}
precis(m8.2)
```
可以看到，估计的参数非常之大，显然这是不正确的。-1和1的均值应该在0附近，所以我们期待的alpha也应该是0. 此外，虽然我们设置了4000次抽样，而最后实际有效样本量却很小（n_eff），同时Rhat也不接近于1. 所以这个模型的链是有严重问题的。

再看一下这个链的路径图。

```{r}
plot(m8.2)
```
可以看到链时不时就会漂移到离均值很远的地方，非常不稳定。

导致这种情况的原因是先验概率过于扁平和观测样本太少。一个扁平的先验概率就意味着参数的每一个值都是有均等的可能性，所以对于alpha，可能有无数个值去进行抽样，这也导致了链非常不稳定，以及产生一些很极端的值，整条链遍布着随机漂移。另外，只有两个样本，数据所能提供的似然性太低，也是导致问题的一个重要原因。

那么该怎么改进呢？其实不难，虽然数据量还是那么多，但是我们可以通过改变先验概率来改进模型。即便是非常弱的先验概率，也能有效的避免在一个无限大的参数空间进行抽样。比如，我们给alpha提供一个Normal(1，10)的先验分布，给sigma提供一个HalfCauchy(0,1)的先验分布。

$$ y_i \sim Normal(\mu,\sigma)$$
$$ \mu=\alpha$$
$$ \alpha \sim Normal(1,10)$$
$$ \sigma \sim HalfCauchy(0,1)$$

```{r}
m8.3 <- map2stan(
 alist(
 y ~ dnorm(mu, sigma),
 mu <- alpha,
 alpha ~ dnorm(1,10),
 sigma ~ dcauchy(0,1)
 ),
 data = list(y=y), start = list(alpha=0, sigma=1),
 chain = 2, iter = 4000, warmup = 1000
)

```
```{r}
precis(m8.3)
```
```{r}
plot(m8.3)
```

这时，再看最后模型拟合的结果，正常多了！不再出现那么极端的结果了。

为什么会出现这种情况，通过下面两张图来看上述模型的先验概率（虚线）和后验概率分布（实线）。

[![qBpbnO.png](https://s1.ax1x.com/2022/03/27/qBpbnO.png)](https://imgtu.com/i/qBpbnO)

可以看出，不管是$\alpha$的先验正态分布，还是$\sigma$的先验Cauchy分布，都是非常弱的先验概率，所以即便整个模型只有两个观测数据（-1和1），模型依旧能够轻松克服先验概率带来的限制。比如我们提供的alpha的先验概率分布均值为1，而模型最终得到了正确的估计结果0。$\sigma$的先验分布在0处取得最大值，但是后验分布的均值约为1.4，观测的标准差约为1.4.但是正是这种很弱的先验概率却十分有效的避免了链的漂移。使得模型认为一个极端大的值不太可能发生。

### 8.5.4 不可估参数

比如有下面一个模型，数据是从Normal(0,1)的正态分布模型中100次随机抽样得到的。其中均值参数是两个参数加和（a1+a2),所以a1和a2是不可识别参数，只有它们的加和是可识别的，而且该加和预期值应该为0。

$$ y_i \sim Normal(\mu,\sigma)$$
$$ \mu = \alpha_1 + \alpha_2$$
$$ \sigma \sim HalfCauchy(0,1)$$

```{r}
y <- rnorm(100,0,1)
m8.4 <- map2stan(
 alist(
 y ~ dnorm(mu, sigma),
 mu <- a1 + a2,
 sigma ~ dcauchy(0,1)
 ),
 data = list(y=y), start = list(a1=0,a2=0,sigma=1),
 chains=2, iter = 4000, warmup = 1000
)

```
```{r}
precis(m8.4)
```
对这个模型进行拟合，根据n_eff和Rhat可以判断，模型非常不好。而且a1和a2是两个非常大的相反值，参数区间非常大。出现这种情况，主要就是a1和a2无法进行估计和识别，只有它俩的加和可以，这也就是它俩加和约等于0的原因。

通过下图，可以看到3个参数的路径图，其中a1和a2两个参数的路径既不稳定也没有很好的一致性。
```{r}
plot(m8.4)
```


而此时如果给两个不可识别的参数加上先验概率分布，会是怎样？

```{r}
y <- rnorm(100,0,1)
m8.5 <- map2stan(
 alist(
 y ~ dnorm(mu,sigma),
 mu <- a1 + a2,
 a1 ~ dnorm(0,10),
 a2 ~ dnorm(0,10),
 sigma ~ dcauchy(0,1)
 ),
 data = list(y=y), start = list(a1=0,a2=0, sigma=1),
 chains=2, iter = 4000, warmup = 1000
)

```
```{r}
precis(m8.5)
```

```{r}
plot(m8.5)
```

从参数估计结果看，已经非常好了，两个参数都变成可以识别的参数了。模型中参数的路径图也变成非常稳定，每个参数的两条链一致性也变得很好了。而改变这一切的原因就是我们添加的先验概率。一个很弱的先验概率拯救了整个模型！

可能有些人会认为上面不可识别的参数$\alpha_1$和$\alpha_2$太容易发现了，自己在建立模型的时候不会出现这种低级失误。但是，如果你建立的模型很复杂，有很多预测变量，特别是在交互作用存在的时候，很容易在模型中出现不可识别参数，而这时就很难发现问题了。所以模型中一定要使用先验概率。同时，使用先验概率也能够加运行速度，告诉马尔可夫链哪儿是合理的参数抽样范围，哪儿不是，从而避免了在一个无限大的空间内很盲目的抽样。

## 8.6总结

本文以形象化的例子介绍了马尔可夫链蒙特卡洛（MCMC）的原理，也简单介绍了三种常用的方法：Metropolis， Gibbs抽样以及Hamiltonian算法。MCMC的转移过程只与邻近状态有关，有之前或之后的状态都不相关，也与初始状态无关。MCMC过程通过不断抽样，达到一个稳定的链，使得参数估计收敛，以此可以很有效的估计出模型参数的后验概率分布，而且该过程不要求具体的后验概率分布类型，不管什么样的后验概率分布都可以使用MCMC。另外，在MCMC过程中，加入适当（哪怕很微弱）的先验概率能够很好的提高运行效率和模型最终效果。





